{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# K-Nearest Neighbour Intuition (K-NN)\n",
    "### NOTE: This version is for CSV file imports!\n",
    "\n",
    "---\n",
    "\n",
    "Created By: Xavier De Carvalho  \n",
    "Created On: 06/07/2021  \n",
    "Upated By: N/A  \n",
    "Updated On: N/A  \n",
    "Version: knn0.0.01\n",
    "\n",
    "### Requirements\n",
    "\n",
    "---\n",
    "\n",
    "##### Required Data Format\n",
    "- File Type: CSV\n",
    "- File Shape: 2 Columns, (n) Rows\n",
    "\n",
    "##### Required Python Packages\n",
    "- Numpy\n",
    "- Matplotlib\n",
    "    - PyPlot\n",
    "    - ListedColormap\n",
    "- Pandas\n",
    "- ScikitLearn\n",
    "    - Model_Selection\n",
    "    - StandardScaler\n",
    "    - KNeighborsClassifier\n",
    "    - confusion_matrix\n",
    "    - accuracy_score\n",
    "\n",
    "### Description\n",
    "\n",
    "---\n",
    "\n",
    "The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems.\n",
    "\n",
    "The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.\n",
    "\n",
    "It's typically best suited to recommender systems.\n",
    "\n",
    "### Steps\n",
    "\n",
    "---\n",
    "\n",
    "- **Step 1** Choose the number K of neighbours\n",
    "- **Step 2** Take the K nearest neighbours of the new data point, according to the Euclidean distance\n",
    "- **Step 3** Among these K neighbours, count the number of data points in each category\n",
    "- **Step 4** Assign the new data point to the category where you counted the most neighbours\n",
    "- **Step 5** Your model is ready"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Install Dependencies If Needed\n",
    "\n",
    "---\n",
    "\n",
    "NOTE: This might not be required if you're running your notebook instance in the cloud! \n",
    "\n",
    "Delete the cell below if this is the case..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the sys dependency\n",
    "import sys\n",
    "# Install dependencies\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install sklearn"
   ]
  },
  {
   "source": [
    "### Import Packages\n",
    "\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrix import confusion_matrix, accuracy_score\n",
    "# Confirm packages have been imported\n",
    "print(\"Packages imported!\")"
   ]
  },
  {
   "source": [
    "### Import the dataset\n",
    "\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "dataset = pd.read_csv('YOUR_CSV')\n",
    "# Allocate X and Y\n",
    "x = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values\n",
    "# Confirm data was imported\n",
    "print(\"Data imported from CSV!\")"
   ]
  },
  {
   "source": [
    "### Create Training set and Test set\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "# Confirm training set was created\n",
    "print(\"Training set created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "source": [
    "### Feature scaling\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "# Confirm feature scaling complete\n",
    "print('Feature scaling complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "source": [
    "### Train the model using the training set\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the test set\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Confirm model was trained\n",
    "print('Model training complete!')"
   ]
  },
  {
   "source": [
    "### Predict a new result\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier.predict(sc.transform([[30,87000]])))"
   ]
  },
  {
   "source": [
    "### Predict the Test set results\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict results for test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Print prediction\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "source": [
    "### Build the confusion matrix\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Confirm cm output\n",
    "print(cm)\n",
    "# Calculate accuracy score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "source": [
    "### Visualise the Training set results\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "X_set, y_set = sc.inverse_transform(X_train), y_train\n",
    "X1, X2 = np.meshgrid(np.arrange(start = X_set[:, 0].min() - 10, stop = X_set[:, 0].max() + 10, step = 1),\n",
    "                     np.arrange(start = X_set[:, 1].min() - 1000, stop = X_set[:, 1].max() + 1000, step = 1))\n",
    "# Plots\n",
    "plt.contourf(X1, X2, classifier.predict(sc.transform(np.array([X1.ravel(), X2.ravel()]).T)).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1], c = ListedColormap(('red', green))(i), label = j)\n",
    "plt.title('K-NN (Training Set)')\n",
    "# Replace the text marked with '@' with your own text.\n",
    "# Don't forget to remove the '@' character!\n",
    "plt.xlabel('@YOUR_X_LABEL')\n",
    "plt.ylabel('@YOUR_Y_LABEL')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ]
}