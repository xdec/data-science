{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "basic_generative_adverserial_network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic GAN (Generative Adverserial Network)\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "## Built with Python and PyTorch\r\n",
        "\r\n",
        "Created By: Xavier De Carvalho     \r\n",
        "Created On: 14/08/2021 20:50PM     \r\n",
        "Upated By: N/A     \r\n",
        "Updated On: N/A     \r\n",
        "Version: GAN0.0.01\r\n",
        "\r\n",
        "### Requirements\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "**Hardware:**\r\n",
        "1. GPU\r\n",
        "\r\n",
        "**Packages:**\r\n",
        "1. PyTorch\r\n",
        "2. Matplotlib\r\n",
        "3. TDQM"
      ],
      "metadata": {
        "id": "_VviYi7SVBFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Packages\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "8LWa7q4CVPgK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Import Packages\r\n",
        "import torch, pdb # PyTorch and Python Debugger\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch import nn\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.datasets import MNIST\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from tqdm.auto import tqdm # Progress Bar\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "print(\"Packages imported!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "D_Q2ntPvU-EO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualization Function\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "PQELMM1dWxAu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Display a grid with generative images vs real images\r\n",
        "def showGrid(tensor, ch=1, size=(28,28), num=16):\r\n",
        "  # Detach variable from gradient computation and pass it to the CPU and restructure it\r\n",
        "  data = tensor.detach().cpu().view(-1, ch, *size)\r\n",
        "  # Make a grid and change order of dimensions\r\n",
        "  grid = make_grid(data[:num], nrow=4).permute(1,2,0) # Order of channels must be reordered to visualize with `plt`\r\n",
        "  plt.imshow(grid)\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "print(\"Visualization function created!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "vDgx18qiWq8A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Params and HyperParams\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VPsdjrxBYkXQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "epochs = 500 # Temporarily hardcoded\r\n",
        "cur_step = 0 # Start current step at 0\r\n",
        "info_step = 300 # Store every (n) steps we want to show about the current loss values, and visualize the images generated by the creator\r\n",
        "\r\n",
        "# Accumulate generator loss and discriminator loss and calculate their mean\r\n",
        "mean_gen_loss = 0\r\n",
        "mean_disc_loss = 0\r\n",
        "\r\n",
        "z_dim = 64 # Latent space dimensionality\r\n",
        "lr = 0.00001 # Learn rate\r\n",
        "loss_func = nn.BCEWithLogitsLoss() # Cross Entropy Loss Function\r\n",
        "\r\n",
        "bs = 128 # Batch size\r\n",
        "device = 'cuda' # Processing device\r\n",
        "\r\n",
        "# Iterator to get training batches\r\n",
        "dataLoader = DataLoader(\r\n",
        "  MNIST('.', download=True, transform=transforms.ToTensor()),\r\n",
        "  shuffle=True,\r\n",
        "  batch_size=bs\r\n",
        ")\r\n",
        "\r\n",
        "print(\"Params and HyperParams set!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "bnJxSEO1Ykpa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator Model\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "I55M_3rIcQX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Generator Block\r\n",
        "def genBlock(inp, out):\r\n",
        "  return nn.Sequential(\r\n",
        "      nn.Linear(inp, out),\r\n",
        "      nn.BatchNorm1d(out), # Normalize values from previous layer to make training more stable\r\n",
        "      nn.ReLU(inplace=True) # Set negatives to zero and only pass positive valyues to create non-linear transformation\r\n",
        "  )\r\n",
        "\r\n",
        "print('genBlock function created!')\r\n",
        "\r\n",
        "# Generator\r\n",
        "class Generator(nn.Module):\r\n",
        "  def __init__(self, z_dim=64, i_dim=784, h_dim=128):\r\n",
        "    super().__init__()\r\n",
        "    self.gen = nn.Sequential(\r\n",
        "        genBlock(z_dim, h_dim), # Input Size is 64 and Exit Size is 128\r\n",
        "        genBlock(h_dim, h_dim*2), # Input Size is 128 and Exit Size is 256\r\n",
        "        genBlock(h_dim*2, h_dim*4), # Input Size is 256 and Exit Size is 512\r\n",
        "        genBlock(h_dim*4, h_dim*8), # Input Size is 512 and Exit Size is 1024\r\n",
        "        nn.Linear(h_dim*8, i_dim), # Input Size 1024 and Exit Size is 784 (28x28) / Size of images in MNIST dataset\r\n",
        "        nn.Sigmoid() # Set values to 0<>1\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, noise):\r\n",
        "    return self.gen(noise)\r\n",
        "\r\n",
        "print('Generator class created!')\r\n",
        "\r\n",
        "# Noise Generator\r\n",
        "def genNoise(number, z_dim):\r\n",
        "  return torch.randn(number, z_dim).to(device) # Run standard normal distribution and store the result in the GPU\r\n",
        "\r\n",
        "print('Noise generator function created!')"
      ],
      "outputs": [],
      "metadata": {
        "id": "qJcEd-4EcTCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator Model\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "As58DaNMfZ1E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Discriminator block\r\n",
        "def discBlock(inp, out):\r\n",
        "  return nn.Sequential(\r\n",
        "      nn.Linear(inp, out),\r\n",
        "      nn.LeakyReLU(0.2) # Prevent neurons from dying by allowing small negative values to pass\r\n",
        "  )\r\n",
        "\r\n",
        "print('discBlock function created!')\r\n",
        "\r\n",
        "#Discriminator\r\n",
        "class Discriminator(nn.Module):\r\n",
        "  def __init__(self, i_dim=784, h_dim=256):\r\n",
        "    super().__init__()\r\n",
        "    self.disc = nn.Sequential(\r\n",
        "        discBlock(i_dim, h_dim*4), # Input Size is 784 and Exit Size is 1024\r\n",
        "        discBlock(h_dim*4, h_dim*2), # Input Size is 1024 and Exit Size is 512\r\n",
        "        discBlock(h_dim*2, h_dim), # Input Size is 512 and Exit Size is 256\r\n",
        "        nn.Linear(h_dim, 1) # Input Size is 256 and Exit Size is 1\r\n",
        "    )\r\n",
        "\r\n",
        "  def forward(self, image):\r\n",
        "    return self.disc(image)\r\n",
        "\r\n",
        "print('Discriminator class created!')"
      ],
      "outputs": [],
      "metadata": {
        "id": "N78nvuSMfYzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer Function\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "KlAD94CGh8kf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Params\r\n",
        "gen = Generator(z_dim).to(device)\r\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\r\n",
        "disc = Discriminator().to(device)\r\n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\r\n",
        "\r\n",
        "print('Optimizer params set!')"
      ],
      "outputs": [],
      "metadata": {
        "id": "287pyMEMh8VO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Show generator structure\r\n",
        "gen"
      ],
      "outputs": [],
      "metadata": {
        "id": "lm5E0BotirGe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Show discriminator structure\r\n",
        "disc"
      ],
      "outputs": [],
      "metadata": {
        "id": "K7LtqusAjGTD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Function\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "nvrmWFT3ju2N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x,y = next(iter(dataLoader)) # Get a batch of 128 images\r\n",
        "# Show the shape of the data\r\n",
        "print(x.shape, y.shape)\r\n",
        "# Show first 10 labels\r\n",
        "print(y[:10])"
      ],
      "outputs": [],
      "metadata": {
        "id": "SGj4QrFEjtqq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Show grid\r\n",
        "noise = genNoise(bs, z_dim)\r\n",
        "fake = gen(noise)\r\n",
        "showGrid(fake)"
      ],
      "outputs": [],
      "metadata": {
        "id": "amCgnCDakJGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate the Loss\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "VLH2pzDJk5IH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Generator Loss\r\n",
        "def calc_gen_loss(loss_func, gen, disc, number, z_dim):\r\n",
        "  gen_noise = genNoise(number, z_dim)\r\n",
        "  gen_fake = gen(gen_noise)\r\n",
        "  gen_pred = disc(gen_fake)\r\n",
        "  gen_targets = torch.ones_like(gen_pred) # Create a tensor with dimensionalities similar to predictions and fill them with 1's\r\n",
        "  gen_loss = loss_func(gen_pred, gen_targets)\r\n",
        "\r\n",
        "  return gen_loss\r\n",
        "\r\n",
        "print('calc_gen_loss function created!')\r\n",
        "\r\n",
        "# Discriminator Loss\r\n",
        "def calc_disc_loss(loss_func, gen, disc, number, real, z_dim):\r\n",
        "  noise = genNoise(number, z_dim)\r\n",
        "  # Fake Images\r\n",
        "  fake = gen(noise)\r\n",
        "  disc_fake = disc(fake.detach()) # Don't change or tweak generator params when backpropogating\r\n",
        "  disc_fake_targets = torch.zeros_like(disc_fake) # Create a tensor with dimensionalities similar to predictions and fill them with 0's\r\n",
        "  disc_fake_loss = loss_func(disc_fake, disc_fake_targets)\r\n",
        "  # Real Images\r\n",
        "  disc_real = disc(real)\r\n",
        "  disc_real_targets = torch.ones_like(disc_real) # Create a tensor with dimensionalities similar to predictions and fill them with 1's\r\n",
        "  disc_real_loss = loss_func(disc_real, disc_real_targets)\r\n",
        "  # Final Loss\r\n",
        "  disc_loss = (disc_fake_loss + disc_real_loss)/2\r\n",
        "\r\n",
        "  return disc_loss\r\n",
        "\r\n",
        "print('calc_disc_loss function created!')"
      ],
      "outputs": [],
      "metadata": {
        "id": "zGJCA0p2k0PN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training The Discriminator Model\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "se--SZB6niw-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Main loop\r\n",
        "for epoch in range(epochs):\r\n",
        "  for real, _ in tqdm(dataLoader):\r\n",
        "    # Discriminator\r\n",
        "    disc_opt.zero_grad() # Set gradient to `0`\r\n",
        "    cur_bs = len(real) # Real: 128*1*28*28\r\n",
        "    real = real.view(cur_bs, -1) # 128*784\r\n",
        "    real = real.to(device)\r\n",
        "    disc_loss = calc_disc_loss(loss_func, gen, disc, cur_bs, real, z_dim)\r\n",
        "    disc_loss.backward(retain_graph=True) # Take the loss value and backpropogate it to calculate the gradients across the NN\r\n",
        "    disc_opt.step() # Tweak and update discriminator params\r\n",
        "\r\n",
        "    # Generator\r\n",
        "    gen_opt.zero_grad() # Set gradient to `0`\r\n",
        "    gen_loss = calc_gen_loss(loss_func, gen, disc, cur_bs, z_dim)\r\n",
        "    gen_loss.backward(retain_graph=True) # Take the loss value and backpropogate it to calculate the gradients across the NN\r\n",
        "    gen_opt.step() # Tweak and update generator params\r\n",
        "\r\n",
        "    # Stats Visualization\r\n",
        "    mean_disc_loss += disc_loss.item()/info_step\r\n",
        "    mean_gen_loss += gen_loss.item()/info_step\r\n",
        "\r\n",
        "    if cur_step % info_step == 0 and cur_step > 0:\r\n",
        "      fake_noise = genNoise(cur_bs, z_dim)\r\n",
        "      fake = gen(fake_noise)\r\n",
        "      showGrid(fake)\r\n",
        "      showGrid(real)\r\n",
        "      print(f\"{epoch}: step {cur_step} / Gen loss: {mean_gen_loss} / disc_loss: {mean_disc_loss}\")\r\n",
        "      mean_gen_loss, mean_disc_loss = 0,0\r\n",
        "    \r\n",
        "    cur_step += 1"
      ],
      "outputs": [],
      "metadata": {
        "id": "Nw4OBH4Onlev"
      }
    }
  ]
}